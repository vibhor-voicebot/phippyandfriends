parameters:
- name: projectName
  displayName: Project Name
  type: string
  default: npmeut
trigger:
  batch: true
  branches:
    include:
    - '*'
  paths:
    include:
    - nodebrady/
pr: none
pool:
  vmImage: ubuntu-latest
variables:
  helmVersion: 3.2.3
  registryServerName: $(registryName).azurecr.io
  projectName: ${{ parameters.projectName }}
  imageName: ${{ parameters.projectName }}
  projectName1: ${{ parameters.projectName }}
  imageTag: $(build.buildId)
  helmChartVersion: $(build.buildId)
  kubeNS: $(k8sNamespace)
  namespaceplaceholder: genpactdde-npmeut  #in orgname-projectname format
  


steps:
- bash: echo '##vso[task.setvariable variable=HELM_EXPERIMENTAL_OCI]1'
  displayName: Set environment variable value for HELM_EXPERIMENTAL_OCI
- bash: echo '##vso[task.setvariable variable=projectName]$(projectName1)'
  displayName: Set environment variable value for projectName
- bash: echo '##vso[task.setvariable variable=kubeNamespace]$(kubeNS)'
  displayName: Set environment variable value for kubeNamespace
- bash: echo "kubeNamespace = $(KUBENAMESPACE)"
- bash: echo "kubeNamespace = $(kubeNamespace)"
- bash: echo "kubeNamespace = $(kubeNS)"
- bash: echo "kubeNamespace = $(namespaceplaceholder)"
- bash: echo "projectName = $(projectName)"
#- bash: 'cd $(projectName) && docker build -t $(registryServerName)/$(imageName):$(imageTag) , ideally we should always use placeholder for projectname while doing cd command..
- bash: 'cd nodebrady && docker build -t $(registryServerName)/$(imageName):$(imageTag)
    .

    '
  failOnStderr: true
  displayName: docker build
- bash: 'echo ''$(registryPassword)'' | docker login $(registryServerName) -u $(registryLogin)
    --password-stdin

    '
  condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))
  displayName: docker login
- bash: 'docker push $(registryServerName)/$(imageName):$(imageTag)

    '
  failOnStderr: true
  condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))
  displayName: docker push
- task: HelmInstaller@1
  displayName: install helm
  inputs:
    helmVersionToInstall: $(helmVersion)
- bash: 'cd nodebrady && helm package --version $(helmChartVersion) --app-version
    $(imageTag) charts/nodebrady

    '
  failOnStderr: true
  displayName: helm package
- bash: 'cd nodebrady && echo ''$(registryPassword)'' | helm registry login $(registryName).azurecr.io
    --username $(registryLogin) --password-stdin  && ls -lrt /home/vsts/work/1/s/
    && helm chart save $(build.sourcesdirectory)/nodebrady/charts/nodebrady/ $(registryServerName)/$(projectName):latest
    && helm chart push $(registryServerName)/$(projectName):latest

    '
  failOnStderr: true
  name: helmPush
  condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))
  displayName: az acr helm push
- publish: $(build.artifactStagingDirectory)
  artifact: build-artifact
  condition: and(succeeded(), eq(variables['build.sourceBranch'], 'refs/heads/master'))
  

- task: HelmInstaller@1
  displayName: 'install helm'
  inputs:
    helmVersionToInstall: $(helmVersion)
- bash: |
   echo "$(aksSpId) | $(aksSpSecret) | $(aksSpTenantId) | kubeNS = $(kubeNS)"
   #az login --service-principal --username $(registryLogin)  --password '$(registryPassword)' --tenant 02f3ad0f-cc97-4a02-b9d8-75e8ddfbea03
   #echo "printing here ACR_Id........."
   #echo $(az acr show -n $(registryName) -g $(rg) --query id -o tsv)


   az login --service-principal --username $(aksSpId) --password $(aksSpSecret) --tenant $(aksSpTenantId)
   echo $(az aks get-credentials  -n $(aks)  -g $(rg))
   #kubeconfigVal=`echo $(az aks get-credentials  -n $(aks)  -g $(rg))  | awk -F"in " '{print $2}'`
   #echo "kubeconfigVal is  $(kubeconfigVal)"
   helm repo add \
        $(registryName) \
        https://$(registryServerName)/helm/v1/repo \
        --username $(registryLogin) \
        --password '$(registryPassword)'
    #helmChartVersion=$(jq .helmChartVersion $(pipeline.workspace)/ci-pipeline/build-artifact/variables.json -r)
    helm repo update
    #helm upgrade --namespace $(kubeNS) --create-namespace  --install  --wait  --version 3.2.3  --set image.repository=$(registryServerName)/$(projectName)  --set ingress.enabled=false  $(projectName)  $(registryServerName)/$(projectName)
    #kubectl get svc,pod,ing --namespace $(kubeNS)
    docker container run -d -it --name $(namespaceplaceholder) $(registryServerName)/$(imageName):$(imageTag)
    echo "sleeping for 20s to let the docker container start & run"
    sleep 20s
    docker container list
    #kubectl delete deployments $(kubeNS)
    #kubectl run $(kubeNS) --image=$(registryServerName)/$(imageName):$(imageTag) --port=6379  --kubeconfig /home/vsts/.kube/config
    rm -rf /home/vsts/.kube/create-ipod.yml
    kubectl delete pod $(namespaceplaceholder)
    echo "Creating image pull secret with kubernetes cluster with sleep 15s.."
    kubectl create secret docker-registry npmeut-acr-secret --namespace $(kubeNS) --docker-server=$(registryName).azurecr.io --docker-username=$(registryLogin) --docker-password=$(registryPassword)
    sleep 15s
    echo -e "apiVersion: v1\nkind: Pod\nmetadata:\n   name: $(projectName)-pod\n   namespace: $(namespaceplaceholder)\nspec:\n   containers:\n    - name: $(namespaceplaceholder)\n      image: $(registryServerName)/$(imageName):latest\n      imagePullPolicy: IfNotPresent\n   imagePullSecrets:\n    - name: $(projectName)-acr-secret" > /home/vsts/.kube/create-ipod.yml
    cat /home/vsts/.kube/create-ipod.yml
    #echo "printing here ACR_Id........."
    #echo $(az acr show -n $(registryName) -g $(rg) --query id -o tsv)
    #az aks update -g $rg -n genpact-npmeut --attach-acr $ACR_ID
    kubectl create -f /home/vsts/.kube/create-ipod.yml
    #kubectl run genpact-uinode1 --image=$(registryServerName)/$(imageName) --port=6379  --kubeconfig /home/vsts/.kube/config
    echo "sleeping for 20s to let the Kubernetes Cluster/Pod start & run"
    sleep 20s    
    kubectl get pods
  failOnStderr: true
  displayName: 'deploy helm chart'

